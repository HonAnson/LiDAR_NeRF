{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "from einops import rearrange, repeat\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preperation (NOTE: Using meter as unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "# convert pointcloud from cartisean coordinate to spherical coordinate\n",
    "def cart2sph(xyz):\n",
    "    x = xyz[:,0]\n",
    "    y = xyz[:,1]\n",
    "    z = xyz[:,2]\n",
    "    XsqPlusYsq = x**2 + y**2\n",
    "    r = np.sqrt(list(XsqPlusYsq + z**2))\n",
    "    elev = np.arctan2(list(z), np.sqrt(list(XsqPlusYsq)))\n",
    "    pan = np.arctan2(list(x), list(y))\n",
    "\n",
    "    output = np.array([r, elev, pan])\n",
    "    return rearrange(output, 'a b -> b a') #take transpose\n",
    "\n",
    "\n",
    "def sph2cart(ang):\n",
    "    ele = ang[:,0]\n",
    "    pan = ang[:,1]\n",
    "    x = np.cos(ele)*np.cos(pan)\n",
    "    y = np.cos(ele)*np.sin(pan)\n",
    "    z = np.sin(ele)\n",
    "    output = np.array([x,y,z])\n",
    "    return rearrange(output, 'a b -> b a') #take transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    # Specify the directory path\n",
    "    dataset_path = 'datasets/testing1'\n",
    "\n",
    "    # List all files in the specified path, ignoring directories\n",
    "    files = [f for f in os.listdir(dataset_path) if os.path.isfile(os.path.join(dataset_path, f))]\n",
    "    files.sort()\n",
    "\n",
    "    # read the files\n",
    "    points_xyz = []\n",
    "    for s in files:\n",
    "        path = 'datasets/testing1/' + s\n",
    "        df = pd.read_csv(path)\n",
    "        a = df.to_numpy()\n",
    "        points_xyz.append(a[:,8:11])\n",
    "    return points_xyz\n",
    "\n",
    "def prepareData(points_xyz):\n",
    "    # Find the fiew direction of each points:\n",
    "    # NOTE: points in spherical coordinate are arranged: [r, elev, pan]\n",
    "    points_sphere = []\n",
    "    for points in points_xyz:\n",
    "        points_sphere.append(cart2sph(points))\n",
    "\n",
    "    ### Process the data\n",
    "    # Translation vectors for points in each view, we are using camera centre at first frame as origin of world coordinate\n",
    "    # NOTE: translation vectors below are found by assuming transformation between frames are translations, and obatined by manually finding corrspondance\n",
    "    # They are translation of the same corrspondance across different frames\n",
    "    # HARD CODED HERE\n",
    "    t0 = np.array([0,0,0])\n",
    "    t1 = np.array([-0.671,-0.016,0.215])\n",
    "    t2 = np.array([-1.825,-0.091,0.147])\n",
    "    t3 = np.array([-2.661,-0.263,0.166])\n",
    "    t4 = np.array([-3.607,-0.156,0.039])\n",
    "    translations = [t0, t1, t2, t3, t4]\n",
    "\n",
    "    # camera centre locations\n",
    "    centres = [-t for t in translations]\n",
    "    centres_data = []\n",
    "    for i,c in enumerate(centres):\n",
    "        l = len(points_sphere[i])\n",
    "        temp = np.tile(c, (l, 1))\n",
    "        centres_data.append(temp)\n",
    "\n",
    "    # stack the points into one big matrix\n",
    "    stacked = []\n",
    "    for i in range(len(points_sphere)):\n",
    "        temp = np.hstack((points_sphere[i], centres_data[i]))\n",
    "        stacked.append(temp)\n",
    "\n",
    "    dataset = np.array([])\n",
    "    for i in range(len(stacked)):\n",
    "        if i == 0:\n",
    "            dataset = stacked[i]\n",
    "        else:\n",
    "            dataset = np.vstack((dataset, stacked[i]))\n",
    "    np.random.shuffle(dataset)\n",
    "\n",
    "    # Mid pass filter, for distance value between 2 and 50 meter\n",
    "    mask1 = dataset[:,0] > 2\n",
    "    dataset = dataset[mask1]\n",
    "    mask2 = dataset[:,0] < 50\n",
    "    dataset = dataset[mask2]\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiDAR_NeRF(nn.Module):\n",
    "    def __init__(self, embedding_dim_pos = 10, embedding_dim_dir = 4, hidden_dim = 256, device = 'cuda'):\n",
    "        super(LiDAR_NeRF, self).__init__()\n",
    "        self.device = device\n",
    "        self.embedding_dim_dir = embedding_dim_dir\n",
    "        self.embedding_dim_pos = embedding_dim_pos\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Linear(embedding_dim_pos * 6 + 3 + embedding_dim_dir * 4 + 2, hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),               \n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),               \n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),               \n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Linear(embedding_dim_pos * 6 + 3 + embedding_dim_dir * 4 + 2 + hidden_dim, hidden_dim), nn.ReLU(),               \n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),               \n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),               \n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim,1)\n",
    "        )\n",
    "        \n",
    "    @staticmethod\n",
    "    def positional_encoding(x, L):\n",
    "        out = [x]\n",
    "        for j in range(L):\n",
    "            out.append(torch.sin(2 ** j * x))\n",
    "            out.append(torch.cos(2 ** j * x))\n",
    "        return torch.cat(out, dim=1)\n",
    "\n",
    "    def forward(self, o, d):\n",
    "        emb_x = self.positional_encoding(o, self.embedding_dim_pos)\n",
    "        emb_d = self.positional_encoding(d, self.embedding_dim_dir)\n",
    "        input = torch.hstack((emb_x,emb_d)).to(dtype=torch.float32)\n",
    "        temp = self.block1(input)\n",
    "        input2 = torch.hstack((temp, input)).to(dtype=torch.float32) # add skip input\n",
    "        output = self.block2(input2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossBCE(rendered_value, actual_value): \n",
    "    loss_bce = nn.CrossEntropyLoss()\n",
    "    loss = loss_bce(rendered_value, actual_value)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4, 9],\n",
       "        [1, 4, 9]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3], [1,2,3]])\n",
    "b = torch.tensor([1,2,3])\n",
    "b*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_positions(origins, angles, ground_truth_distance, num_bins = 100, device = 'cpu'):\n",
    "    elev = angles[:,0]\n",
    "    pan = angles[:,1]\n",
    "    dir_x = torch.tensor(np.cos(elev)*np.cos(pan))      # [batch_size]\n",
    "    dir_y = torch.tensor(np.cos(elev)*np.sin(pan))      # [batch_size]\n",
    "    dir_z = torch.tensor(np.sin(elev))\n",
    "    gt_tensor = torch.tensor(ground_truth_distance)\n",
    "    # create a list of magnitudes with even spacing\n",
    "    t = torch.linspace(0,1, num_bins, device=device).expand(dir_x.shape[0], num_bins)  # [batch_size, num_bins]\n",
    "    \n",
    "    # preterb the spacing\n",
    "    mid = (t[:, :-1] + t[:, 1:]) / 2.\n",
    "    lower = torch.cat((t[:, :1], mid), -1)\n",
    "    upper = torch.cat((mid, t[:, -1:]), -1)\n",
    "    u = torch.rand(t.shape, device = device)\n",
    "    t = lower + (upper - lower) * u  # [batch_size, nb_bins]\n",
    "    t = rearrange(t, 'a b -> b a')  # [num_bins, batch_size]  take transpose so that multiplication can broadcast\n",
    "\n",
    "    # convert magnitudes into positions by multiplying unit vector in each direction\n",
    "    t = gt_tensor*t\n",
    "    t += 3\n",
    "    print(t[0:10])\n",
    "    pos_x = dir_x*t     # [num_bins, batch_size]\n",
    "    pos_y = dir_y*t\n",
    "    pos_z = dir_z*t\n",
    "    multiplied = rearrange([pos_x,pos_y,pos_z], 'c b n  -> (n b) c')   # [num_bin*batchsize, 3]\n",
    "    # tile the origin values\n",
    "    origins_tiled = repeat(origins, 'n c -> (n b) c', b = num_bins) # [num_bin*batch_size, 3]\n",
    "    pos = torch.tensor(origins_tiled) + multiplied\n",
    "    # tile the angle too\n",
    "    angles_tiled = torch.tensor(repeat(angles, 'n c -> (n b) c', b = num_bins))\n",
    "    return pos, angles_tiled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns pytorch tensor of sigmoid of projected SDF\n",
    "def get_actual_value(sample_positions, gt_distance, num_bins=100):\n",
    "    # tile distances\n",
    "    gt_distance_tiled = repeat(gt_distance, 'b -> (b n) 1', n=num_bins)\n",
    "    # calculate distance from sample_position\n",
    "    temp = torch.tensor(sample_positions**2)\n",
    "    pos_distance = torch.sqrt(torch.sum(temp, dim=1, keepdim=True))\n",
    "    # find the \"projected\" value\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    values = sigmoid(-(pos_distance - gt_distance_tiled))\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0030, 0.0076, 0.0216,  ..., 0.9846, 0.9881, 0.9962],\n",
      "        [0.0025, 0.0146, 0.0194,  ..., 0.9788, 0.9908, 0.9951],\n",
      "        [0.0036, 0.0057, 0.0157,  ..., 0.9754, 0.9850, 0.9970],\n",
      "        ...,\n",
      "        [0.0027, 0.0084, 0.0182,  ..., 0.9835, 0.9938, 0.9953],\n",
      "        [0.0048, 0.0103, 0.0214,  ..., 0.9782, 0.9875, 0.9976],\n",
      "        [0.0024, 0.0054, 0.0185,  ..., 0.9821, 0.9914, 0.9976]])\n"
     ]
    }
   ],
   "source": [
    "# sample data for testing\n",
    "points = loadData()\n",
    "dataset = prepareData(points)\n",
    "test_batch = dataset[128:256,:]\n",
    "ground_truth_distance = test_batch[:,0]\n",
    "angles = test_batch[:,1:3]\n",
    "origin = test_batch[:,3:]\n",
    "pos, ang = get_sample_positions(origin, angles, ground_truth_distance ,num_bins=100)\n",
    "\n",
    "# model = LiDAR_NeRF(hidden_dim=256)\n",
    "# rendered = model(pos, ang)\n",
    "# sigmoid = nn.Sigmoid()\n",
    "# rendered_sigmoid = sigmoid(rendered)\n",
    "# temp = torch.zeros_like(pos)\n",
    "# val = (get_actual_value(pos, ground_truth_distance)).to(dtype = torch.float32)\n",
    "\n",
    "# for x in val:\n",
    "#     print(x)\n",
    "# print(min(rendered))\n",
    "# loss_bce = nn.BCELoss()\n",
    "# loss = loss_bce(rendered_sigmoid, val)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.08749442e+01, -1.74584083e-02, -2.60536143e+00,  1.82500000e+00,\n",
       "        9.10000000e-02, -1.47000000e-01])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.8211,  -1.4816,  -0.2007],\n",
       "        [ -1.1420,  -1.6724,  -0.2073],\n",
       "        [ -1.2672,  -1.7467,  -0.2098],\n",
       "        [ -1.4977,  -1.8837,  -0.2145],\n",
       "        [ -1.7401,  -2.0278,  -0.2194],\n",
       "        [ -1.9713,  -2.1652,  -0.2241],\n",
       "        [ -2.2443,  -2.3275,  -0.2297],\n",
       "        [ -2.6005,  -2.5392,  -0.2369],\n",
       "        [ -2.9988,  -2.7759,  -0.2450],\n",
       "        [ -3.1157,  -2.8454,  -0.2474],\n",
       "        [ -3.4188,  -3.0255,  -0.2535],\n",
       "        [ -3.8068,  -3.2561,  -0.2614],\n",
       "        [ -3.9411,  -3.3359,  -0.2641],\n",
       "        [ -4.1091,  -3.4358,  -0.2675],\n",
       "        [ -4.3958,  -3.6061,  -0.2734],\n",
       "        [ -4.8995,  -3.9055,  -0.2836],\n",
       "        [ -5.0136,  -3.9733,  -0.2859],\n",
       "        [ -5.3558,  -4.1767,  -0.2929],\n",
       "        [ -5.6384,  -4.3446,  -0.2986],\n",
       "        [ -5.7712,  -4.4236,  -0.3013],\n",
       "        [ -6.1726,  -4.6621,  -0.3094],\n",
       "        [ -6.2843,  -4.7285,  -0.3117],\n",
       "        [ -6.5544,  -4.8890,  -0.3172],\n",
       "        [ -6.8827,  -5.0842,  -0.3239],\n",
       "        [ -7.1331,  -5.2329,  -0.3289],\n",
       "        [ -7.3780,  -5.3785,  -0.3339],\n",
       "        [ -7.7613,  -5.6063,  -0.3417],\n",
       "        [ -8.1190,  -5.8189,  -0.3490],\n",
       "        [ -8.2769,  -5.9127,  -0.3522],\n",
       "        [ -8.4684,  -6.0266,  -0.3561],\n",
       "        [ -8.7960,  -6.2213,  -0.3627],\n",
       "        [ -9.1782,  -6.4484,  -0.3705],\n",
       "        [ -9.4138,  -6.5884,  -0.3753],\n",
       "        [ -9.5668,  -6.6794,  -0.3784],\n",
       "        [ -9.9154,  -6.8866,  -0.3855],\n",
       "        [-10.1454,  -7.0232,  -0.3901],\n",
       "        [-10.5364,  -7.2556,  -0.3981],\n",
       "        [-10.5582,  -7.2686,  -0.3985],\n",
       "        [-10.9845,  -7.5219,  -0.4072],\n",
       "        [-11.3220,  -7.7225,  -0.4140],\n",
       "        [-11.3669,  -7.7492,  -0.4149],\n",
       "        [-11.7786,  -7.9939,  -0.4233],\n",
       "        [-12.1284,  -8.2017,  -0.4304],\n",
       "        [-12.2730,  -8.2877,  -0.4333],\n",
       "        [-12.5703,  -8.4644,  -0.4394],\n",
       "        [-12.8249,  -8.6157,  -0.4446],\n",
       "        [-13.1426,  -8.8045,  -0.4510],\n",
       "        [-13.2476,  -8.8669,  -0.4531],\n",
       "        [-13.6733,  -9.1199,  -0.4618],\n",
       "        [-13.7633,  -9.1734,  -0.4636],\n",
       "        [-14.2701,  -9.4746,  -0.4739],\n",
       "        [-14.4606,  -9.5878,  -0.4778],\n",
       "        [-14.6024,  -9.6721,  -0.4807],\n",
       "        [-14.9012,  -9.8497,  -0.4867],\n",
       "        [-15.1952, -10.0244,  -0.4927],\n",
       "        [-15.4673, -10.1861,  -0.4982],\n",
       "        [-15.7139, -10.3327,  -0.5032],\n",
       "        [-16.0441, -10.5289,  -0.5099],\n",
       "        [-16.4172, -10.7507,  -0.5175],\n",
       "        [-16.5887, -10.8526,  -0.5210],\n",
       "        [-16.8044, -10.9808,  -0.5254],\n",
       "        [-17.0004, -11.0973,  -0.5294],\n",
       "        [-17.3461, -11.3027,  -0.5364],\n",
       "        [-17.6681, -11.4941,  -0.5429],\n",
       "        [-17.7905, -11.5669,  -0.5454],\n",
       "        [-18.0923, -11.7462,  -0.5515],\n",
       "        [-18.5101, -11.9945,  -0.5600],\n",
       "        [-18.6488, -12.0769,  -0.5628],\n",
       "        [-18.8626, -12.2040,  -0.5672],\n",
       "        [-19.3157, -12.4733,  -0.5764],\n",
       "        [-19.5014, -12.5837,  -0.5802],\n",
       "        [-19.7638, -12.7396,  -0.5855],\n",
       "        [-20.0868, -12.9316,  -0.5921],\n",
       "        [-20.3544, -13.0906,  -0.5975],\n",
       "        [-20.5408, -13.2014,  -0.6013],\n",
       "        [-20.8881, -13.4078,  -0.6083],\n",
       "        [-21.0000, -13.4743,  -0.6106],\n",
       "        [-21.3988, -13.7114,  -0.6187],\n",
       "        [-21.6056, -13.8342,  -0.6229],\n",
       "        [-21.8864, -14.0011,  -0.6286],\n",
       "        [-22.0817, -14.1172,  -0.6326],\n",
       "        [-22.4728, -14.3496,  -0.6405],\n",
       "        [-22.8273, -14.5603,  -0.6477],\n",
       "        [-22.9126, -14.6110,  -0.6494],\n",
       "        [-23.3490, -14.8704,  -0.6583],\n",
       "        [-23.5665, -14.9996,  -0.6627],\n",
       "        [-23.7927, -15.1341,  -0.6673],\n",
       "        [-23.9890, -15.2507,  -0.6713],\n",
       "        [-24.3115, -15.4424,  -0.6779],\n",
       "        [-24.5485, -15.5832,  -0.6827],\n",
       "        [-24.9486, -15.8211,  -0.6908],\n",
       "        [-25.1756, -15.9560,  -0.6954],\n",
       "        [-25.4615, -16.1259,  -0.7012],\n",
       "        [-25.7193, -16.2791,  -0.7065],\n",
       "        [-25.9579, -16.4209,  -0.7113],\n",
       "        [-26.0995, -16.5050,  -0.7142],\n",
       "        [-26.3586, -16.6590,  -0.7194],\n",
       "        [-26.7271, -16.8780,  -0.7269],\n",
       "        [-27.0479, -17.0687,  -0.7334],\n",
       "        [-27.1601, -17.1354,  -0.7357]], dtype=torch.float64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[100:200,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, dataloader, device = 'cpu', epoch = int(1e5), num_bins = 100):\n",
    "    training_losses = []\n",
    "    for _ in tqdm(range(epoch)):\n",
    "        for batch in dataloader:\n",
    "            # parse the batch\n",
    "            ground_truth_distance = batch[:,0]\n",
    "            angles = batch[:,1:3]\n",
    "            origin = batch[:,:3:7]\n",
    "            \n",
    "            sample_positions, sample_angles = get_sample_positions(origin, angles, num_bins=num_bins)\n",
    "            \n",
    "            rendered_value = model(sample_positions.to(device), sample_angles.to(device))\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            rendered_value_sigmoid = sigmoid(rendered_value)\n",
    "            actual_value_sigmoided = (get_actual_value(sample_positions.to(device), ground_truth_distance.to(device))).to(dtype = torch.float32)\n",
    "            \n",
    "            # loss = lossBCE(rendered_value, actual_value_sigmoided)  # + lossEikonal(model)\n",
    "            # loss_bce = nn.CrossEntropyLoss()\n",
    "            loss_bce = nn.BCELoss()\n",
    "            loss = loss_bce(rendered_value_sigmoid, actual_value_sigmoided)\n",
    "            # BCEWithLogitsLoss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_losses.append(loss.item())\n",
    "            # print(loss.item())\n",
    "            print(loss.item())\n",
    "        scheduler.step()\n",
    "    return training_losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device} device\")\n",
    "points = loadData()\n",
    "print(\"loaded data\")\n",
    "data_matrix = prepareData(points)\n",
    "print(\"prepared data\")\n",
    "training_dataset = torch.from_numpy(data_matrix)\n",
    "data_loader = DataLoader(training_dataset, batch_size=1024, shuffle = True)\n",
    "model = LiDAR_NeRF(hidden_dim=512, embedding_dim_dir=10, device = device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[2, 4, 8, 16], gamma=0.5)\n",
    "losses = train(model, optimizer, scheduler, data_loader, epoch = 20, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the model\n",
    "torch.save(model.state_dict(), 'version1_trial1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LiDAR_NeRF(\n",
       "  (block1): Sequential(\n",
       "    (0): Linear(in_features=105, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Linear(in_features=617, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Load the model and try to \"visualize\" the model's datapoints\n",
    "model2 = LiDAR_NeRF(hidden_dim=512, embedding_dim_dir=10, device = 'cpu')\n",
    "model2.load_state_dict(torch.load('/home/ansonhon/anson/thesis/LiDAR_NeRF/local/models/version1_trial1.pth'))\n",
    "model2.eval()  # Set the model to inference mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7409/2962768184.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  temp = torch.tensor(sample_positions**2)\n",
      "/tmp/ipykernel_7409/3574676403.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_tensor = torch.tensor(pos)\n",
      "/tmp/ipykernel_7409/3574676403.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ang_tensor = torch.tensor(ang)\n"
     ]
    }
   ],
   "source": [
    "# sample data for testing\n",
    "points = loadData()\n",
    "dataset = prepareData(points)\n",
    "test_batch = dataset[0:128,:]\n",
    "ground_truth_distance = test_batch[:,0]\n",
    "angles = test_batch[:,1:3]\n",
    "origin = test_batch[:,3:]\n",
    "pos, ang = get_sample_positions(origin, angles,num_bins=100)\n",
    "# ang[:,1] += 0.01\n",
    "model = LiDAR_NeRF(hidden_dim=256)\n",
    "rendered = model(pos, ang)\n",
    "sigmoid = nn.Sigmoid()\n",
    "rendered_sigmoid = sigmoid(rendered)\n",
    "# pos = torch.zeros_like(pos)\n",
    "val = (get_actual_value(pos, ground_truth_distance)).to(dtype = torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pos_tensor = torch.tensor(pos)\n",
    "    ang_tensor = torch.tensor(ang)\n",
    "    output = model2(pos_tensor, ang_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.399214  , 10.91817829, 13.53060871,  6.07898947, 11.7334501 ,\n",
       "        9.37332625,  8.71858306,  8.13654893,  8.60786704, 11.26260301,\n",
       "        6.61249818, 24.06703704, 15.54482499,  9.59759753, 27.90561933,\n",
       "       38.18257097, 49.65299743, 27.85560469, 12.63629208,  9.20088626,\n",
       "       15.04839681,  8.09782063,  7.96666677,  5.78550798, 37.44105097,\n",
       "        4.78177721, 13.00769447, 13.22598086, 12.09721827, 10.75251612,\n",
       "        9.25793713, 24.2170193 , 13.9909485 ,  8.85495899,  9.80638234,\n",
       "       49.63953668, 21.07629429, 43.70530456,  6.25467492, 33.22301242,\n",
       "        9.33456179,  6.39301065, 48.02704691, 23.29812176,  4.17582805,\n",
       "       13.57226488, 18.06122046,  7.88255098, 10.0327647 , 18.31223302,\n",
       "        5.91224103, 12.04290148, 15.78143721, 12.58434868, 16.93181907,\n",
       "       10.78562153,  7.13742712, 19.47748405, 23.78903986,  6.67717171,\n",
       "       11.44818246, 11.44713756, 20.59084911,  4.50917099, 36.92286079,\n",
       "       15.31491297,  6.34567305, 15.13709847, 31.7577729 ,  6.55110849,\n",
       "       14.1766872 , 33.93032215, 40.30843064, 13.05559618, 16.34571656,\n",
       "       22.4093526 , 12.86785855,  8.84925565, 10.09933529, 18.57246115,\n",
       "       23.12021463, 14.67214825, 34.14015456, 31.14688106, 11.86048795,\n",
       "       11.58627925, 16.84166164, 11.11649224,  6.47469333, 11.37357401,\n",
       "       19.37642598, 12.00676906, 10.29031011, 21.23577674,  8.29601591,\n",
       "       14.60039267, 35.49199167, 28.96416878, 10.8833557 , 37.96336443,\n",
       "        7.97066663,  4.2185032 ,  7.11916782, 44.33565   , 12.78581019,\n",
       "        7.26831601, 14.49289394, 31.4721046 , 48.38402794, 15.51204036,\n",
       "        6.54165269,  7.69110906,  7.21911976,  7.79806193,  5.65628157,\n",
       "        7.53984124, 31.5214893 , 12.15965378,  6.99089242, 47.58827312,\n",
       "       24.43215807,  8.50587347,  8.4187877 , 33.06710569, 14.17791869,\n",
       "       15.95151072, 17.7087446 , 16.32354788])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  3.1185,  -0.5239,  -0.6558],\n",
      "        [  3.5806,  -0.6015,  -0.7530],\n",
      "        [  4.5801,  -0.7695,  -0.9632],\n",
      "        [  5.0458,  -0.8477,  -1.0611],\n",
      "        [  5.6898,  -0.9559,  -1.1966],\n",
      "        [  6.1265,  -1.0293,  -1.2884],\n",
      "        [  7.3240,  -1.2304,  -1.5403],\n",
      "        [  7.7609,  -1.3038,  -1.6322],\n",
      "        [  8.3259,  -1.3987,  -1.7510],\n",
      "        [  9.4974,  -1.5956,  -1.9973],\n",
      "        [ 10.1525,  -1.7056,  -2.1351],\n",
      "        [ 10.6502,  -1.7892,  -2.2398],\n",
      "        [ 11.1054,  -1.8657,  -2.3355],\n",
      "        [ 12.0142,  -2.0184,  -2.5266],\n",
      "        [ 12.3803,  -2.0799,  -2.6036],\n",
      "        [ 13.4859,  -2.2656,  -2.8361],\n",
      "        [ 14.3389,  -2.4089,  -3.0155],\n",
      "        [ 15.0206,  -2.5235,  -3.1589],\n",
      "        [ 15.5355,  -2.6100,  -3.2672],\n",
      "        [ 15.9780,  -2.6843,  -3.3602],\n",
      "        [ 16.9162,  -2.8419,  -3.5576],\n",
      "        [ 17.9054,  -3.0081,  -3.7656],\n",
      "        [ 18.4689,  -3.1028,  -3.8841],\n",
      "        [ 19.0608,  -3.2022,  -4.0086],\n",
      "        [ 19.8788,  -3.3396,  -4.1806],\n",
      "        [ 20.6663,  -3.4719,  -4.3462],\n",
      "        [ 20.9212,  -3.5148,  -4.3998],\n",
      "        [ 22.1533,  -3.7217,  -4.6589],\n",
      "        [ 22.5137,  -3.7823,  -4.7347],\n",
      "        [ 22.9465,  -3.8550,  -4.8258],\n",
      "        [ 24.2781,  -4.0787,  -5.1058],\n",
      "        [ 24.5152,  -4.1186,  -5.1557],\n",
      "        [ 25.6408,  -4.3076,  -5.3924],\n",
      "        [ 26.1917,  -4.4002,  -5.5082],\n",
      "        [ 26.4967,  -4.4514,  -5.5724],\n",
      "        [ 27.3276,  -4.5910,  -5.7471],\n",
      "        [ 28.1997,  -4.7376,  -5.9305],\n",
      "        [ 28.7918,  -4.8370,  -6.0551],\n",
      "        [ 29.3875,  -4.9371,  -6.1803],\n",
      "        [ 30.3057,  -5.0914,  -6.3734],\n",
      "        [ 31.0424,  -5.2151,  -6.5284],\n",
      "        [ 32.0360,  -5.3820,  -6.7373],\n",
      "        [ 32.1906,  -5.4080,  -6.7699],\n",
      "        [ 33.2505,  -5.5861,  -6.9927],\n",
      "        [ 33.8638,  -5.6891,  -7.1217],\n",
      "        [ 34.4351,  -5.7851,  -7.2419],\n",
      "        [ 35.3369,  -5.9366,  -7.4315],\n",
      "        [ 35.5651,  -5.9749,  -7.4795],\n",
      "        [ 36.3431,  -6.1056,  -7.6431],\n",
      "        [ 37.3752,  -6.2790,  -7.8602],\n",
      "        [ 38.0241,  -6.3880,  -7.9966],\n",
      "        [ 38.5047,  -6.4688,  -8.0977],\n",
      "        [ 39.2725,  -6.5978,  -8.2592],\n",
      "        [ 39.9526,  -6.7120,  -8.4022],\n",
      "        [ 40.5309,  -6.8092,  -8.5238],\n",
      "        [ 41.7367,  -7.0118,  -8.7774],\n",
      "        [ 42.0164,  -7.0587,  -8.8362],\n",
      "        [ 42.9382,  -7.2136,  -9.0301],\n",
      "        [ 43.5829,  -7.3219,  -9.1657],\n",
      "        [ 44.2095,  -7.4272,  -9.2975],\n",
      "        [ 44.9471,  -7.5511,  -9.4526],\n",
      "        [ 45.4499,  -7.6356,  -9.5583],\n",
      "        [ 46.4144,  -7.7976,  -9.7612],\n",
      "        [ 47.1006,  -7.9129,  -9.9055],\n",
      "        [ 47.8911,  -8.0457, -10.0717],\n",
      "        [ 48.2699,  -8.1093, -10.1514],\n",
      "        [ 48.9044,  -8.2159, -10.2848],\n",
      "        [ 49.6224,  -8.3365, -10.4358],\n",
      "        [ 50.5400,  -8.4907, -10.6288],\n",
      "        [ 51.6042,  -8.6695, -10.8526],\n",
      "        [ 52.2783,  -8.7827, -10.9944],\n",
      "        [ 52.7991,  -8.8702, -11.1039],\n",
      "        [ 53.1586,  -8.9306, -11.1795],\n",
      "        [ 53.9608,  -9.0654, -11.3482],\n",
      "        [ 54.7747,  -9.2021, -11.5194],\n",
      "        [ 55.7601,  -9.3677, -11.7266],\n",
      "        [ 56.2252,  -9.4458, -11.8244],\n",
      "        [ 56.6756,  -9.5215, -11.9192],\n",
      "        [ 57.4663,  -9.6543, -12.0854],\n",
      "        [ 58.7054,  -9.8625, -12.3460],\n",
      "        [ 59.1582,  -9.9386, -12.4413],\n",
      "        [ 59.5343, -10.0017, -12.5204],\n",
      "        [ 60.5305, -10.1691, -12.7299],\n",
      "        [ 61.4337, -10.3209, -12.9198],\n",
      "        [ 61.6354, -10.3547, -12.9622],\n",
      "        [ 62.7679, -10.5450, -13.2004],\n",
      "        [ 63.6258, -10.6891, -13.3808],\n",
      "        [ 64.2469, -10.7935, -13.5114],\n",
      "        [ 64.6847, -10.8670, -13.6035],\n",
      "        [ 65.6011, -11.0210, -13.7962],\n",
      "        [ 65.9160, -11.0739, -13.8625],\n",
      "        [ 66.4629, -11.1658, -13.9775],\n",
      "        [ 67.5755, -11.3527, -14.2115],\n",
      "        [ 68.2614, -11.4679, -14.3557],\n",
      "        [ 68.8715, -11.5704, -14.4840],\n",
      "        [ 69.4225, -11.6630, -14.5999],\n",
      "        [ 70.2663, -11.8047, -14.7774],\n",
      "        [ 70.8964, -11.9106, -14.9099],\n",
      "        [ 71.4374, -12.0015, -15.0236],\n",
      "        [ 72.2279, -12.1343, -15.1899]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(pos[0:100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.2275e-01],\n",
      "        [-1.0635e+00],\n",
      "        [-1.3142e+00],\n",
      "        [-1.7705e+00],\n",
      "        [-2.5884e+00],\n",
      "        [-3.0063e+00],\n",
      "        [-3.6417e+00],\n",
      "        [-4.4365e+00],\n",
      "        [-4.8669e+00],\n",
      "        [-5.4820e+00],\n",
      "        [-6.4632e+00],\n",
      "        [-6.6659e+00],\n",
      "        [-7.2081e+00],\n",
      "        [-8.4017e+00],\n",
      "        [-8.9906e+00],\n",
      "        [-9.6592e+00],\n",
      "        [-1.0285e+01],\n",
      "        [-1.0843e+01],\n",
      "        [-1.1799e+01],\n",
      "        [-1.3038e+01],\n",
      "        [-1.3060e+01],\n",
      "        [-1.3554e+01],\n",
      "        [-1.4500e+01],\n",
      "        [-1.5559e+01],\n",
      "        [-1.6112e+01],\n",
      "        [-1.6187e+01],\n",
      "        [-1.6843e+01],\n",
      "        [-1.7287e+01],\n",
      "        [-1.7841e+01],\n",
      "        [-1.8358e+01],\n",
      "        [-1.9024e+01],\n",
      "        [-1.9419e+01],\n",
      "        [-2.0323e+01],\n",
      "        [-2.1107e+01],\n",
      "        [-2.1104e+01],\n",
      "        [-2.1432e+01],\n",
      "        [-2.1914e+01],\n",
      "        [-2.2501e+01],\n",
      "        [-2.2534e+01],\n",
      "        [-2.3445e+01],\n",
      "        [-2.3725e+01],\n",
      "        [-2.4523e+01],\n",
      "        [-2.4248e+01],\n",
      "        [-2.4803e+01],\n",
      "        [-2.4973e+01],\n",
      "        [-2.5085e+01],\n",
      "        [-2.5937e+01],\n",
      "        [-2.6064e+01],\n",
      "        [-2.6358e+01],\n",
      "        [-2.7235e+01],\n",
      "        [-2.7222e+01],\n",
      "        [-2.7837e+01],\n",
      "        [-2.7893e+01],\n",
      "        [-2.8010e+01],\n",
      "        [-2.8387e+01],\n",
      "        [-2.9011e+01],\n",
      "        [-2.9526e+01],\n",
      "        [-2.9669e+01],\n",
      "        [-2.9999e+01],\n",
      "        [-3.0660e+01],\n",
      "        [-3.1099e+01],\n",
      "        [-3.1626e+01],\n",
      "        [-3.1983e+01],\n",
      "        [-3.2298e+01],\n",
      "        [-3.2714e+01],\n",
      "        [-3.3777e+01],\n",
      "        [-3.4219e+01],\n",
      "        [-3.4872e+01],\n",
      "        [-3.5240e+01],\n",
      "        [-3.5424e+01],\n",
      "        [-3.6119e+01],\n",
      "        [-3.6237e+01],\n",
      "        [-3.6689e+01],\n",
      "        [-3.6788e+01],\n",
      "        [-3.7754e+01],\n",
      "        [-3.8126e+01],\n",
      "        [-3.8609e+01],\n",
      "        [-3.9685e+01],\n",
      "        [-4.0291e+01],\n",
      "        [-4.1006e+01],\n",
      "        [-4.1199e+01],\n",
      "        [-4.2467e+01],\n",
      "        [-4.2468e+01],\n",
      "        [-4.2422e+01],\n",
      "        [-4.3509e+01],\n",
      "        [-4.4146e+01],\n",
      "        [-4.4537e+01],\n",
      "        [-4.4797e+01],\n",
      "        [-4.5180e+01],\n",
      "        [-4.5993e+01],\n",
      "        [-4.6473e+01],\n",
      "        [-4.7312e+01],\n",
      "        [-4.8182e+01],\n",
      "        [-4.7967e+01],\n",
      "        [-4.8655e+01],\n",
      "        [-4.9427e+01],\n",
      "        [-4.9855e+01],\n",
      "        [-5.0886e+01],\n",
      "        [-5.0772e+01],\n",
      "        [-5.0109e+01],\n",
      "        [ 4.7876e-01],\n",
      "        [ 2.9359e-01],\n",
      "        [ 2.9420e-02],\n",
      "        [-1.4574e-01],\n",
      "        [-3.7174e-01],\n",
      "        [-8.8851e-01],\n",
      "        [-1.2901e+00],\n",
      "        [-1.9961e+00],\n",
      "        [-2.5571e+00],\n",
      "        [-2.4716e+00],\n",
      "        [-2.6389e+00],\n",
      "        [-3.6088e+00],\n",
      "        [-4.6853e+00],\n",
      "        [-4.9997e+00],\n",
      "        [-6.0789e+00],\n",
      "        [-6.0310e+00],\n",
      "        [-6.2972e+00],\n",
      "        [-6.9677e+00],\n",
      "        [-7.9867e+00],\n",
      "        [-8.2893e+00],\n",
      "        [-8.8150e+00],\n",
      "        [-8.9374e+00],\n",
      "        [-9.4911e+00],\n",
      "        [-9.8220e+00],\n",
      "        [-1.0573e+01],\n",
      "        [-1.0731e+01],\n",
      "        [-1.1559e+01],\n",
      "        [-1.1615e+01],\n",
      "        [-1.1410e+01],\n",
      "        [-1.2225e+01],\n",
      "        [-1.2814e+01],\n",
      "        [-1.3485e+01],\n",
      "        [-1.3690e+01],\n",
      "        [-1.4157e+01],\n",
      "        [-1.4252e+01],\n",
      "        [-1.4377e+01],\n",
      "        [-1.4514e+01],\n",
      "        [-1.4987e+01],\n",
      "        [-1.5567e+01],\n",
      "        [-1.5549e+01],\n",
      "        [-1.6462e+01],\n",
      "        [-1.6548e+01],\n",
      "        [-1.7451e+01],\n",
      "        [-1.7477e+01],\n",
      "        [-1.7586e+01],\n",
      "        [-1.7983e+01],\n",
      "        [-1.7942e+01],\n",
      "        [-1.7853e+01],\n",
      "        [-1.8689e+01],\n",
      "        [-1.8539e+01],\n",
      "        [-1.8960e+01],\n",
      "        [-1.9047e+01],\n",
      "        [-1.9696e+01],\n",
      "        [-2.0748e+01],\n",
      "        [-2.0638e+01],\n",
      "        [-2.0891e+01],\n",
      "        [-2.1364e+01],\n",
      "        [-2.1561e+01],\n",
      "        [-2.1887e+01],\n",
      "        [-2.2131e+01],\n",
      "        [-2.2338e+01],\n",
      "        [-2.2972e+01],\n",
      "        [-2.2986e+01],\n",
      "        [-2.3357e+01],\n",
      "        [-2.3314e+01],\n",
      "        [-2.4421e+01],\n",
      "        [-2.4824e+01],\n",
      "        [-2.4787e+01],\n",
      "        [-2.5247e+01],\n",
      "        [-2.5508e+01],\n",
      "        [-2.6167e+01],\n",
      "        [-2.6191e+01],\n",
      "        [-2.6001e+01],\n",
      "        [-2.6249e+01],\n",
      "        [-2.7028e+01],\n",
      "        [-2.6876e+01],\n",
      "        [-2.7815e+01],\n",
      "        [-2.8296e+01],\n",
      "        [-2.8555e+01],\n",
      "        [-2.8605e+01],\n",
      "        [-2.9135e+01],\n",
      "        [-2.9509e+01],\n",
      "        [-2.9748e+01],\n",
      "        [-3.0125e+01],\n",
      "        [-3.0516e+01],\n",
      "        [-3.0687e+01],\n",
      "        [-3.0981e+01],\n",
      "        [-3.1164e+01],\n",
      "        [-3.1492e+01],\n",
      "        [-3.2529e+01],\n",
      "        [-3.2552e+01],\n",
      "        [-3.2759e+01],\n",
      "        [-3.3262e+01],\n",
      "        [-3.3211e+01],\n",
      "        [-3.4037e+01],\n",
      "        [-3.4220e+01],\n",
      "        [-3.4479e+01],\n",
      "        [-3.4267e+01],\n",
      "        [-3.4997e+01],\n",
      "        [-3.4606e+01]])\n"
     ]
    }
   ],
   "source": [
    "print(output[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    dist = 1 # initial distanc forvisualization\n",
    "    pos = torch.zeros((100000,3))\n",
    "    ele = torch.linspace(-0.34, 0.3, 100)\n",
    "    pan = torch.linspace(-3.14, 3.14, 1000)\n",
    "    ele_tiled = repeat(ele, 'n -> (r n) 1', r = 1000)\n",
    "    pan_tiled = repeat(pan, 'n -> (n r) 1', r = 100)\n",
    "    ang = torch.cat((ele_tiled, pan_tiled), dim=1)\n",
    "\n",
    "    # direction for each \"point\" from camera centre\n",
    "    directions = torch.tensor(sph2cart(np.array(ang)))\n",
    "\n",
    "    \n",
    "\n",
    "    # for i in range(50):\n",
    "    #     output2 = model2(pos, ang)\n",
    "    #     temp = torch.sign(output2)\n",
    "    #     pos += directions * dist * temp\n",
    "    #     # dist /= 2\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Version  Slot ID  LiDAR Index  Rsvd  Error Code  Timestamp Type  Data Type  \\\n",
      "0        5        7            1     0  0x00000200               0          0   \n",
      "1        5        7            1     0  0x00000200               0          0   \n",
      "2        5        7            1     0  0x00000200               0          0   \n",
      "3        5        7            1     0  0x00000200               0          0   \n",
      "4        5        7            1     0  0x00000200               0          0   \n",
      "\n",
      "      Timestamp         X         Y         Z  Reflectivity  Tag  Ori_x  \\\n",
      "0  339330000000 -7.542027 -0.012011 -2.667897            24    0   8128   \n",
      "1  339330000000 -7.559117 -0.012038 -2.619085            24    0   8132   \n",
      "2  339330000000 -5.681918 -0.009049 -1.927623            24    0   8137   \n",
      "3  339330000000 -5.694260 -0.009068 -1.890851            28    0   8132   \n",
      "4  339330000000 -5.706365 -0.009088 -1.854000            28    0   8132   \n",
      "\n",
      "   Ori_y  Ori_z  Ori_radius  Ori_theta  Ori_phi  \n",
      "0  23651   6826           0          0        0  \n",
      "1  23653   6788           0          0        0  \n",
      "2  23661   6751           0          0        0  \n",
      "3  23646   6707           0          0        0  \n",
      "4  23642   6665           0          0        0  \n"
     ]
    }
   ],
   "source": [
    "### Save to csv for visualization\n",
    "df_temp = pd.read_csv('datasets/testing1/testing.csv')\n",
    "df_temp = df_temp.head(100000)\n",
    "pos_np = pos.numpy()\n",
    "df_temp['X'] = pos_np[:,0]\n",
    "df_temp['Y'] = pos_np[:,1]\n",
    "df_temp['Z'] = pos_np[:,2]\n",
    "print(df_temp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.to_csv('testing.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar_nerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
