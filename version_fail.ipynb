{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "from einops import rearrange\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from scipy.special import sph_harm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preperation (NOTE: Using meter as unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pointcloud from cartisean coordinate to spherical coordinate\n",
    "def cart2sph(xyz):\n",
    "    x = xyz[:,0]\n",
    "    y = xyz[:,1]\n",
    "    z = xyz[:,2]\n",
    "    XsqPlusYsq = x**2 + y**2\n",
    "    r = np.sqrt(list(XsqPlusYsq + z**2))\n",
    "    elev = np.arctan2(list(z), np.sqrt(list(XsqPlusYsq)))\n",
    "    pan = np.arctan2(list(x), list(y))\n",
    "    output = np.array([r, elev, pan])\n",
    "    return rearrange(output, 'a b -> b a') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory path\n",
    "dataset_path = 'datasets/testing1'\n",
    "\n",
    "# List all files in the specified path, ignoring directories\n",
    "files = [f for f in os.listdir(dataset_path) if os.path.isfile(os.path.join(dataset_path, f))]\n",
    "files.sort()\n",
    "\n",
    "# read the files\n",
    "points_xyz = []\n",
    "for s in files:\n",
    "    path = 'datasets/testing1/' + s\n",
    "    df = pd.read_csv(path)\n",
    "    a = df.to_numpy()\n",
    "    b = a[:,8:11]\n",
    "    points_xyz.append(b)\n",
    "\n",
    "# Now we can find the fiew direction of each points:\n",
    "# NOTE: points in spherical coordinate are arranged: [r, elev, pan]\n",
    "points_sphere = []\n",
    "for points in points_xyz:\n",
    "    points_sphere.append(cart2sph(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### we now process the data\n",
    "# Translation vectors for points in each view, we are using camera centre at first frame as origin of world coordinate\n",
    "# NOTE: translation vectors below are found by assuming transformation between frames are translations, and obatined by manually finding corrspondance\n",
    "# They are translation of the same corrspondance across different frames\n",
    "# HARD CODED HERE\n",
    "t0 = np.array([0,0,0])\n",
    "t1 = np.array([-0.671,-0.016,0.215])\n",
    "t2 = np.array([-1.825,-0.091,0.147])\n",
    "t3 = np.array([-2.661,-0.263,0.166])\n",
    "t4 = np.array([-3.607,-0.156,0.039])\n",
    "translations = [t0, t1, t2, t3, t4]\n",
    "\n",
    "# camera centre locations\n",
    "centres = [-t for t in translations]\n",
    "centres_data = []\n",
    "for i,c in enumerate(centres):\n",
    "    l = len(points_sphere[i])\n",
    "    temp = np.tile(c, (l, 1))\n",
    "    centres_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the points into one big matrix\n",
    "stacked = []\n",
    "for i in range(len(points_sphere)):\n",
    "    temp = np.hstack((points_sphere[i], centres_data[i]))\n",
    "    stacked.append(temp)\n",
    "\n",
    "dataset = np.array([])\n",
    "for i in range(len(stacked)):\n",
    "    if i == 0:\n",
    "        dataset = stacked[i]\n",
    "    else:\n",
    "        dataset = np.vstack((dataset, stacked[i]))\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "# Filter out points where the distance value is = 0\n",
    "mask1 = dataset[:, 0] != 0\n",
    "mask2 = dataset[:,0] > 50\n",
    "mask = mask1 + mask2\n",
    "dataset = dataset[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele = dataset[:,1]\n",
    "pan = dataset[:,2]\n",
    "ele = ele + np.pi / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum degree of harmonics\n",
    "l_max = 8\n",
    "num_features = sum(2 * l + 1 for l in range(l_max + 1))\n",
    "features = np.zeros((dataset.shape[0], num_features))\n",
    "feature_idx = 0\n",
    "for l in range(l_max + 1):\n",
    "    for m in range(-l, l + 1):\n",
    "        Y_lm = sph_harm(m, l, pan, ele)\n",
    "        features[:, feature_idx] = Y_lm.real  # Storing real part, or use absolute values, etc.\n",
    "        feature_idx += 1\n",
    "\n",
    "a = rearrange(dataset[:,0], 'a -> a 1')\n",
    "encoded_data = np.hstack((a,features, dataset[:,3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now prepare to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset to pytorch tensor\n",
    "X = np.array(encoded_data[:,1:])\n",
    "y = np.array(encoded_data[:,0])\n",
    "\n",
    "# Convert to tensor:\n",
    "X_tensor = torch.from_numpy(X).double()\n",
    "y_tensor = torch.from_numpy(y).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we prepare to train the model\n",
    "features = 5\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(features, 512),  # Input layer with 5 inputs and 10 outputs\n",
    "            nn.ReLU(),                # Activation function\n",
    "            nn.Linear(512, 512),        # Hidden layer with 512 neurons\n",
    "            nn.ReLU(),                # Activation function\n",
    "            nn.Linear(512, 512),        # Hidden layer with 512 neurons\n",
    "            nn.ReLU(),                # Activation function\n",
    "            nn.Linear(512, 512),        # Hidden layer with 512 neurons\n",
    "            nn.ReLU(),                # Activation function\n",
    "            nn.Linear(512, 512),        # Hidden layer with 512 neurons\n",
    "            nn.ReLU(),                # Activation function\n",
    "            nn.Linear(512, 1)          # Output layer with 1 output\n",
    "        )\n",
    "    \n",
    "    @staticmethod                               \n",
    "    def sph_harm_emb(x, L):\n",
    "        pan = x[0]\n",
    "        ele = x[1]\n",
    "        out = []\n",
    "        out.append(pan)\n",
    "        out.append(ele)\n",
    "        num_features = sum(2 * l + 1 for l in range(L + 1))\n",
    "        for l in range(L + 1):\n",
    "            for m in range(-l, l + 1):\n",
    "                Y_lm = sph_harm(m, l, pan, ele)\n",
    "                out.append(Y_lm.real)  \n",
    "        return torch.tensor(out)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        angles = x[0:2]\n",
    "        origin = x[2:]\n",
    "        emb_angle = self.sph_harm_emb(angles, 8)\n",
    "        temp = torch.cat(emb_angle, origin, axis=0)\n",
    "        return self.layers(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat(), targets\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/lidar_nerf/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/lidar_nerf/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 39\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m angles \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     38\u001b[0m origin \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m---> 39\u001b[0m emb_angle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msph_harm_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mangles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m temp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(emb_angle, origin, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(temp)\n",
      "Cell \u001b[0;32mIn[50], line 31\u001b[0m, in \u001b[0;36mMLP.sph_harm_emb\u001b[0;34m(x, L)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(L \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m-\u001b[39ml, l \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 31\u001b[0m         Y_lm \u001b[38;5;241m=\u001b[39m \u001b[43msph_harm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mele\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m         out\u001b[38;5;241m.\u001b[39mappend(Y_lm\u001b[38;5;241m.\u001b[39mreal)  \n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(out)\n",
      "File \u001b[0;32m~/anaconda3/envs/lidar_nerf/lib/python3.10/site-packages/torch/_tensor.py:1087\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1087\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "batch_size = 256\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "# Initialize the model\n",
    "model = MLP().to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = inputs.to(device).float(), targets.to(device).float()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar_nerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
