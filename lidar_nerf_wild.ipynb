{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "from einops import rearrange, repeat\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "#test update for branch wild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preperation (NOTE: Using meter as unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "# convert pointcloud from cartisean coordinate to spherical coordinate\n",
    "def cart2sph(xyz):\n",
    "    x = xyz[:,0]\n",
    "    y = xyz[:,1]\n",
    "    z = xyz[:,2]\n",
    "    XsqPlusYsq = x**2 + y**2\n",
    "    r = np.sqrt(list(XsqPlusYsq + z**2))\n",
    "    elev = np.arctan2(list(z), np.sqrt(list(XsqPlusYsq)))\n",
    "    pan = np.arctan2(list(x), list(y))\n",
    "\n",
    "    output = np.array([r, elev, pan])\n",
    "    return rearrange(output, 'a b -> b a') #take transpose\n",
    "\n",
    "\n",
    "def sph2cart(ang):\n",
    "    ele = ang[:,0]\n",
    "    pan = ang[:,1]\n",
    "    x = np.cos(ele)*np.cos(pan)\n",
    "    y = np.cos(ele)*np.sin(pan)\n",
    "    z = np.sin(ele)\n",
    "    output = np.array([x,y,z])\n",
    "    return rearrange(output, 'a b -> b a') #take transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    # Specify the directory path\n",
    "    dataset_path = 'datasets/testing1'\n",
    "\n",
    "    # List all files in the specified path, ignoring directories\n",
    "    files = [f for f in os.listdir(dataset_path) if os.path.isfile(os.path.join(dataset_path, f))]\n",
    "    files.sort()\n",
    "\n",
    "    # read the files\n",
    "    points_xyz = []\n",
    "    for s in files:\n",
    "        path = 'datasets/testing1/' + s\n",
    "        df = pd.read_csv(path)\n",
    "        a = df.to_numpy()\n",
    "        points_xyz.append(a[:,8:11])\n",
    "    return points_xyz\n",
    "\n",
    "def prepareData(points_xyz):\n",
    "    # Find the fiew direction of each points:\n",
    "    # NOTE: points in spherical coordinate are arranged: [r, elev, pan]\n",
    "    points_sphere = []\n",
    "    for points in points_xyz:\n",
    "        points_sphere.append(cart2sph(points))\n",
    "\n",
    "    ### Process the data\n",
    "    # Translation vectors for points in each view, we are using camera centre at first frame as origin of world coordinate\n",
    "    # NOTE: translation vectors below are found by assuming transformation between frames are translations, and obatined by manually finding corrspondance between frames\n",
    "    # They are translation of the same corrspondance across different frames\n",
    "    # HARD CODED HERE...\n",
    "    t0 = np.array([0,0,0])\n",
    "    t1 = np.array([-0.671,-0.016,0.215])\n",
    "    t2 = np.array([-1.825,-0.091,0.147])\n",
    "    t3 = np.array([-2.661,-0.263,0.166])\n",
    "    t4 = np.array([-3.607,-0.156,0.039])\n",
    "    # ...TO HERE\n",
    "    translations = [t0, t1, t2, t3, t4]\n",
    "\n",
    "    # camera centre locations\n",
    "    centres = [-t for t in translations]\n",
    "    centres_data = []\n",
    "    for i,c in enumerate(centres):\n",
    "        l = len(points_sphere[i])\n",
    "        temp = np.tile(c, (l, 1))\n",
    "        centres_data.append(temp)\n",
    "\n",
    "    # stack the points into one big matrix\n",
    "    stacked = []\n",
    "    for i in range(len(points_sphere)):\n",
    "        temp = np.hstack((points_sphere[i], centres_data[i]))\n",
    "        stacked.append(temp)\n",
    "\n",
    "    dataset = np.array([])\n",
    "    for i in range(len(stacked)):\n",
    "        if i == 0:\n",
    "            dataset = stacked[i]\n",
    "        else:\n",
    "            dataset = np.vstack((dataset, stacked[i]))\n",
    "\n",
    "\n",
    "    np.random.shuffle(dataset)\n",
    "\n",
    "    # Mid pass filter, for distance value between 2 and 50 meter\n",
    "    mask1 = dataset[:,0] > 2\n",
    "    dataset = dataset[mask1]\n",
    "    mask2 = dataset[:,0] < 50\n",
    "    dataset = dataset[mask2]\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiDAR_NeRF(nn.Module):\n",
    "    def __init__(self, embedding_dim_pos = 10, embedding_dim_dir = 4, hidden_dim = 256, device = 'cuda'):\n",
    "        super(LiDAR_NeRF, self).__init__()\n",
    "        self.device = device\n",
    "        self.embedding_dim_dir = embedding_dim_dir\n",
    "        self.embedding_dim_pos = embedding_dim_pos\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Linear(embedding_dim_pos * 6 + 3 + embedding_dim_dir * 4 + 2, hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),               \n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),               \n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),               \n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Linear(embedding_dim_pos * 6 + 3 + embedding_dim_dir * 4 + 2 + hidden_dim, hidden_dim), nn.ReLU(),               \n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),               \n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),               \n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),\n",
    "            nn.Linear(hidden_dim,1)\n",
    "        )\n",
    "        \n",
    "    @staticmethod\n",
    "    def positional_encoding(x, L):\n",
    "        out = [x]\n",
    "        for j in range(L):\n",
    "            out.append(torch.sin(2 ** j * x))\n",
    "            out.append(torch.cos(2 ** j * x))\n",
    "        return torch.cat(out, dim=1)\n",
    "\n",
    "    def forward(self, o, d):\n",
    "        emb_x = self.positional_encoding(o, self.embedding_dim_pos)\n",
    "        emb_d = self.positional_encoding(d, self.embedding_dim_dir)\n",
    "        input = torch.hstack((emb_x,emb_d)).to(dtype=torch.float32)\n",
    "        temp = self.block1(input)\n",
    "        input2 = torch.hstack((temp, input)).to(dtype=torch.float32) # add skip input\n",
    "        output = self.block2(input2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSamples(origins, angles, ground_truth_distance, num_bins = 100):\n",
    "    elev = angles[:,0]\n",
    "    pan = angles[:,1]\n",
    "    dir_x = torch.tensor(np.cos(elev)*np.cos(pan))      # [batch_size]\n",
    "    dir_y = torch.tensor(np.cos(elev)*np.sin(pan))      # [batch_size]\n",
    "    dir_z = torch.tensor(np.sin(elev))\n",
    "    gt_tensor = torch.tensor(ground_truth_distance)\n",
    "    # create a list of magnitudes with even spacing from 0 to 1\n",
    "    t = torch.linspace(0,1, num_bins).expand(dir_x.shape[0], num_bins)  # [batch_size, num_bins]\n",
    "    \n",
    "    # preterb the spacing\n",
    "    mid = (t[:, :-1] + t[:, 1:]) / 2.\n",
    "    lower = torch.cat((t[:, :1], mid), -1)\n",
    "    upper = torch.cat((mid, t[:, -1:]), -1)\n",
    "    u = torch.rand(t.shape)\n",
    "    t = lower + (upper - lower) * u  # [batch_size, nb_bins]\n",
    "    t = rearrange(t, 'a b -> b a')  # [num_bins, batch_size]  take transpose so that multiplication can broadcast\n",
    "    \n",
    "    # multiply the magnitude to ground truth distance and add 3 meter\n",
    "    t = torch.sqrt(t)\n",
    "    t = gt_tensor*t\n",
    "    t += 10\n",
    "\n",
    "    # convert magnitudes into positions by multiplying it to the unit vector\n",
    "    pos_x = dir_x*t     # [num_bins, batch_size]\n",
    "    pos_y = dir_y*t\n",
    "    pos_z = dir_z*t\n",
    "    # concat them for output\n",
    "    multiplied = rearrange([pos_x,pos_y,pos_z], 'c b n  -> (n b) c')   # [num_bin*batchsize, 3]\n",
    "    # tile the origin values\n",
    "    origins_tiled = repeat(origins, 'n c -> (n b) c', b = num_bins) # [num_bin*batch_size, 3]\n",
    "    pos = torch.tensor(origins_tiled) + multiplied\n",
    "    # tile the angle too\n",
    "    angles_tiled = torch.tensor(repeat(angles, 'n c -> (n b) c', b = num_bins))\n",
    "    return pos, angles_tiled, origins_tiled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming a and b are tensors of shape [100, 5]\n",
    "a = torch.randn(100, 5)\n",
    "b = torch.randn(100, 5)\n",
    "\n",
    "# Extract the first column of both tensors\n",
    "a_first_column = a[:, 0]\n",
    "b_first_column = b[:, 0]\n",
    "\n",
    "# Create masks for the rows where a's first column is greater than or equal to b's\n",
    "greater_mask = a_first_column >= b_first_column\n",
    "\n",
    "# Use the mask to select rows from each tensor\n",
    "max_rows = torch.where(greater_mask.unsqueeze(1), a, b)\n",
    "min_rows = torch.where(greater_mask.unsqueeze(1), b, a)\n",
    "\n",
    "# max_rows and min_rows are tensors of shape [100, 5]\n",
    "print(\"Rows with max elements based on first column comparison:\", max_rows)\n",
    "print(\"Rows with min elements based on first column comparison:\", min_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greater_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUpSamples(origins, angles, gt_distance, num_rolls = 1):\n",
    "\n",
    "    for num_roll in range(1, num_rolls+1):\n",
    "        # prepare data for \n",
    "        origins_a = torch.vstack((origins, torch.roll(origins, num_roll, 1)))\n",
    "        origins_b = torch.vstack((torch.roll(origins, num_roll, 1), origins))\n",
    "\n",
    "        angles_a = torch.vstack((angles, torch.roll(angles,num_roll, 1)))\n",
    "        angles_b = torch.vstack((torch.roll(angles,num_roll, 1), angles))\n",
    "\n",
    "        gt_distance_a = torch.vstack((gt_distance, torch.roll(gt_distance, num_roll, 1)))\n",
    "        gt_distance_b = torch.vstack((torch.roll(gt_distance, num_roll, 1), gt_distance))\n",
    "\n",
    "        dir = torch.tensor(sph2cart(angles))\n",
    "        gt_distance = rearrange(gt_distance, 'a -> a 1')\n",
    "        pos = gt_distance * dir\n",
    "        pos_a = torch.vstack()\n",
    "            \n",
    "            \n",
    "        # check if angle between pairs are small\n",
    "        diff = torch.abs(angles_a - angles_b)\n",
    "        mask_small_ang = (diff < 0.09).all(dim=1)   ### NOTE: hardcoded 0.09 radient difference max\n",
    "\n",
    "        # check if origin between pairs are small\n",
    "        diff2 = torch.abs(origins_a - origins_b)\n",
    "        mask_small_org = (diff2 < 0.2).all(dim=1)\n",
    "        \n",
    "        # check if the target location is close\n",
    "        diff3 = torch.abs(pos - torch.roll(pos, num_roll, 0))\n",
    "        mask_small_dis = (diff3 < 0.2).all(dim=1)\n",
    "\n",
    "        # indicator of if the left side is the \"shorter\" ray\n",
    "        left_bigger = (gt_distance > torch.roll(gt_distance, num_roll, 0))\n",
    "        right_bigger = (gt_distance < torch.roll(gt_distance, num_roll, 0))\n",
    "\n",
    "        mask_same_org1 = mask_small_ang & mask_small_org & left_bigger\n",
    "        mask_same_org2 = mask_small_ang & mask_small_org & right_bigger\n",
    "\n",
    "        mask_same_tag = mask_small_ang & mask_small_dis\n",
    "\n",
    "\n",
    "        ### Handling case of same origin\n",
    "        # prepare set where rays are to be upsampled \n",
    "        # ensuring samples are at rays that are longer\n",
    "        angles_from_same_org1 = angles[mask_same_org1]\n",
    "        origins_from_same_org1 = origins[mask_same_org1]\n",
    "        pos_to1 = (torch.roll(pos, num_roll, 0))[mask_same_org1]\n",
    "        angles_from_same_org2 = (torch.roll(angles,num_roll,0))[mask_same_org2]\n",
    "        origins_from_same_org2 = (torch.roll(origins, num_roll, 0))[mask_same_org2]\n",
    "        pos_to2 = pos[mask_same_org2]\n",
    "        \n",
    "\n",
    "        angles_from_same_org =   \n",
    "\n",
    "        if angles_from_same_org.shape[0] == 0:\n",
    "            return torch.empty(0, 3), torch.empty(0, 2), torch.empty(0,1)   # return empty tensor if nothing matches upsample requirement\n",
    "\n",
    "        # calculate upsampling position\n",
    "        num_bins = 20 \n",
    "        t = torch.linspace(0,1, num_bins).expand(angles_from_same_org.shape[0], num_bins)  # [batch_size, num_bins]\n",
    "        \n",
    "        # preterb the spacing\n",
    "        mid = (t[:, :-1] + t[:, 1:]) / 2.\n",
    "        lower = torch.cat((t[:, :1], mid), -1)\n",
    "        upper = torch.cat((mid, t[:, -1:]), -1)\n",
    "        u = torch.rand(t.shape)\n",
    "        t = lower + (upper - lower) * u  # [batch_size, nb_bins]\n",
    "        t = rearrange(t, 'a b -> b a')  # [num_bins, batch_size]  take transpose so that multiplication can broadcast\n",
    "        t = rearrange(t, 'a b -> (b a) 1')\n",
    "\n",
    "        # get the sampling positions\n",
    "        origins_from_tiled = repeat(origins_from_same_org, 'n c -> (n b) c', b = num_bins)\n",
    "        dir_from = torch.tensor(sph2cart(angles_from_same_org))\n",
    "        dir_from_tiled = repeat(dir_from, 'n c -> (n b) c', b = num_bins)\n",
    "\n",
    "        pos_from = origins_from_tiled + dir_from_tiled * t * 5       ### HARDCODED 5 here as the range where we upsample our positions (for now)\n",
    "        pos_to_tiled = repeat(pos_to, 'n c -> (n b) c', b = num_bins)\n",
    "\n",
    "        # calculate direction \n",
    "        sample_sph = cart2sph(pos_from - pos_to_tiled)\n",
    "        sample_direction = sample_sph[:,1:]\n",
    "        sample_gt_distance = sample_sph[:,0]\n",
    "\n",
    "        # add one more dimension to sample_gt_distance\n",
    "        sample_gt_distance = rearrange(sample_gt_distance, 'a -> a 1')\n",
    "\n",
    "    return pos_from , torch.tensor(sample_direction), torch.tensor(sample_gt_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns pytorch tensor of sigmoid of projected SDF\n",
    "def getTargetValues(sample_positions, gt_distance, origins, num_bins=100):\n",
    "    # calculate distance from sample_position\n",
    "    temp = torch.tensor((sample_positions - origins)**2)\n",
    "    pos_distance = torch.sqrt(torch.sum(temp, dim=1, keepdim=True))\n",
    "    \n",
    "    # find the \"projected\" value\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    values = sigmoid(-(pos_distance - gt_distance))\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # constants\n",
    "# num_bins = 100\n",
    "# device = 'cuda'\n",
    "\n",
    "# # sample data for testing\n",
    "# points = loadData()\n",
    "# dataset = prepareData(points)\n",
    "# test_batch = torch.tensor(dataset[0:256,:])\n",
    "# gt_distance = test_batch[:,0]\n",
    "# angles = test_batch[:,1:3]\n",
    "# origins = test_batch[:,3:6]\n",
    "# upsample_pos, upsample_ang, upsample_gt_distance = getUpSamples(origins, angles,  gt_distance)\n",
    "# sample_pos, sample_ang, sample_org = getSamples(origins, angles, gt_distance, num_bins = num_bins)\n",
    "# gt_distance_tiled = repeat(gt_distance, 'b -> (b n) 1', n = num_bins)\n",
    "\n",
    "# # stack the upsampled position to sampled positions\n",
    "# pos = (torch.vstack((sample_pos, upsample_pos))).to(device)\n",
    "# ang = (torch.vstack((sample_ang, upsample_ang))).to(device)\n",
    "# gt_dis = (torch.vstack((gt_distance_tiled,upsample_gt_distance) )).to(device)\n",
    "# org = (torch.vstack((sample_org, upsample_pos))).to(device)\n",
    "\n",
    "# # inference and training\n",
    "# model = LiDAR_NeRF(hidden_dim=512)\n",
    "# rendered_value = model(pos, ang)\n",
    "# sigmoid = nn.Sigmoid()\n",
    "# rendered_value_sigmoid = sigmoid(rendered_value)\n",
    "# actual_value_sigmoided = (getTargetValues(pos, gt_dis, org)).to(dtype = torch.float32)\n",
    "# # loss = lossBCE(rendered_value, actual_value_sigmoided)  # + lossEikonal(model)\n",
    "# loss_bce = nn.BCELoss()\n",
    "# loss = loss_bce(rendered_value_sigmoid, actual_value_sigmoided)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, dataloader, device = 'cuda', epoch = int(1e5), num_bins = 100):\n",
    "    training_losses = []\n",
    "    for _ in tqdm(range(epoch)):\n",
    "        for batch in dataloader:\n",
    "            # parse the batch\n",
    "            ground_truth_distance = batch[:,0]\n",
    "            angles = batch[:,1:3]\n",
    "            origins = batch[:,3:6]\n",
    "            upsample_pos, upsample_ang, upsample_gt_distance = getUpSamples(origins, angles, ground_truth_distance, num_roll=10)\n",
    "            sample_pos, sample_ang, sample_org = getSamples(origins, angles, ground_truth_distance, num_bins=num_bins)\n",
    "            # tile distances\n",
    "            gt_distance_tiled = repeat(ground_truth_distance, 'b -> (b n) 1', n=num_bins)\n",
    "\n",
    "            # stack the upsampled position to sampled positions\n",
    "            pos = (torch.vstack((sample_pos, upsample_pos))).to(device)\n",
    "            ang = (torch.vstack((sample_ang, upsample_ang))).to(device)\n",
    "            gt_dis = (torch.vstack((gt_distance_tiled,upsample_gt_distance))).to(device)\n",
    "            org = (torch.vstack((sample_org, upsample_pos))).to(device)\n",
    "            \n",
    "            # inference and training\n",
    "            rendered_value = model(pos, ang)\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            rendered_value_sigmoid = sigmoid(rendered_value)\n",
    "            actual_value_sigmoided = (getTargetValues(pos, gt_dis, org)).to(dtype = torch.float32)\n",
    "            # loss = lossBCE(rendered_value, actual_value_sigmoided)  # + lossEikonal(model)\n",
    "            loss_bce = nn.BCELoss()\n",
    "            loss = loss_bce(rendered_value_sigmoid, actual_value_sigmoided)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_losses.append(loss.item())\n",
    "        scheduler.step()\n",
    "        print(loss.item())\n",
    "    return training_losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "loaded data\n",
      "prepared data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/tmp/ipykernel_10040/452579322.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dir_x = torch.tensor(np.cos(elev)*np.cos(pan))      # [batch_size]\n",
      "/tmp/ipykernel_10040/452579322.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dir_y = torch.tensor(np.cos(elev)*np.sin(pan))      # [batch_size]\n",
      "/tmp/ipykernel_10040/452579322.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dir_z = torch.tensor(np.sin(elev))\n",
      "/tmp/ipykernel_10040/452579322.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gt_tensor = torch.tensor(ground_truth_distance)\n",
      "/tmp/ipykernel_10040/452579322.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos = torch.tensor(origins_tiled) + multiplied\n",
      "/tmp/ipykernel_10040/452579322.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  angles_tiled = torch.tensor(repeat(angles, 'n c -> (n b) c', b = num_bins))\n",
      " 12%|█▎        | 1/8 [03:12<22:30, 192.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14833222329616547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [06:25<19:15, 192.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13577798008918762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [09:37<16:02, 192.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13381460309028625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [12:51<12:52, 193.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11695846915245056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [16:08<09:43, 194.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12252667546272278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [19:24<06:29, 194.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1169440895318985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [22:40<03:15, 195.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1229114830493927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [25:55<00:00, 194.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11599234491586685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device} device\")\n",
    "points = loadData()\n",
    "print(\"loaded data\")\n",
    "data_matrix = prepareData(points)\n",
    "print(\"prepared data\")\n",
    "training_dataset = torch.from_numpy(data_matrix)\n",
    "data_loader = DataLoader(training_dataset, batch_size=1024, shuffle = True)\n",
    "model = LiDAR_NeRF(hidden_dim=512, embedding_dim_dir=15, device = device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[2, 4, 8, 16], gamma=0.5)\n",
    "losses = train(model, optimizer, scheduler, data_loader, epoch = 8, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Save the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal/models/version2_trial1.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "### Save the model\n",
    "torch.save(model.state_dict(), 'local/models/version2_trial1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load the model and try to \"visualize\" the model's datapoints\n",
    "model_evel = LiDAR_NeRF(hidden_dim=512, embedding_dim_dir=15, device = 'cpu')\n",
    "model_evel.load_state_dict(torch.load('local/models/version2_trial1.pth'))\n",
    "model_evel.eval(); # Set the model to inference mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Render some structured pointcloud for evaluation\n",
    "with torch.no_grad():\n",
    "    dist = 0.1 # initial distanc forvisualization\n",
    "    pos = torch.zeros((100000,3))\n",
    "    ele = torch.linspace(-0.34, 0.3, 100)\n",
    "    pan = torch.linspace(-3.14, 3.14, 1000)\n",
    "    ele_tiled = repeat(ele, 'n -> (r n) 1', r = 1000)\n",
    "    pan_tiled = repeat(pan, 'n -> (n r) 1', r = 100)\n",
    "    ang = torch.cat((ele_tiled, pan_tiled), dim=1)\n",
    "\n",
    "    # direction for each \"point\" from camera centre\n",
    "    directions = torch.tensor(sph2cart(np.array(ang)))\n",
    "\n",
    "    for i in range(500):\n",
    "        output2 = model_evel(pos, ang)\n",
    "        temp = torch.sign(output2)\n",
    "        pos += directions * dist * temp\n",
    "        # dist /= 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Render some structured pointcloud for evaluation\n",
    "with torch.no_grad():\n",
    "    dist = 32 # initial distanc forvisualization\n",
    "    pos = torch.zeros((100000,3))\n",
    "    pos[:,1] += 5\n",
    "    ele = torch.linspace(-0.34, 0.3, 100)\n",
    "    pan = torch.linspace(-3.14, 3.14, 1000)\n",
    "    ele_tiled = repeat(ele, 'n -> (r n) 1', r = 1000)\n",
    "    pan_tiled = repeat(pan, 'n -> (n r) 1', r = 100)\n",
    "    ang = torch.cat((ele_tiled, pan_tiled), dim=1)\n",
    "\n",
    "    # direction for each \"point\" from camera centre\n",
    "    directions = torch.tensor(sph2cart(np.array(ang)))\n",
    "\n",
    "    for i in range(10):\n",
    "        output2 = model_evel(pos, ang)\n",
    "        temp = torch.sign(output2)\n",
    "        pos += directions * dist * temp\n",
    "        dist /= 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save to csv for visualization\n",
    "df_temp = pd.read_csv('local/visualize/dummy.csv')\n",
    "df_temp = df_temp.head(100000)\n",
    "pos_np = pos.numpy()\n",
    "df_temp['X'] = pos_np[:,0]\n",
    "df_temp['Y'] = pos_np[:,1]\n",
    "df_temp['Z'] = pos_np[:,2]\n",
    "df_temp.to_csv('local/visualize/visualize.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar_nerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
