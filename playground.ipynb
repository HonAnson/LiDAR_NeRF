{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange, repeat\n",
    "import rosbags\n",
    "import json\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "from utility import listFiles\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from numpy import cos, sin\n",
    "import torch.nn as nn\n",
    "### fucking around\n",
    "from pretrain import loadDataFromRegisteredSlam, cart2sph, preProcess\n",
    "from train import getSamples, getUpSamples, getSpacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data ... (1200/1203)"
     ]
    }
   ],
   "source": [
    "name = r'box_plant2'\n",
    "path = r'datasets/registered/' + name + r'.json'\n",
    "data = loadDataFromRegisteredSlam(path)\n",
    "training_data = preProcess(data)\n",
    "np.random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 10240\n",
    "sample_magnitude = training_data[:num_points,0]\n",
    "sample_magnitude = rearrange(sample_magnitude, 'n -> n 1')\n",
    "angles = training_data[:num_points,1:3]\n",
    "origins = training_data[:num_points,3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = angles[:,0]\n",
    "pan = angles[:,1]\n",
    "### Return angles back to directions\n",
    "x_tilde, y_tilde, z_tilde = cos(elev)*cos(pan), cos(elev)*sin(pan), sin(elev)      \n",
    "unit_vectors = np.vstack((x_tilde, y_tilde, z_tilde))\n",
    "unit_vectors = rearrange(unit_vectors, 'a b -> b a')\n",
    "pos = unit_vectors*sample_magnitude + origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ground_truth_distance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gt_dist_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mground_truth_distance\u001b[49m)\n\u001b[1;32m      2\u001b[0m ang_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(angles)\n\u001b[1;32m      3\u001b[0m origins_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(origins)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ground_truth_distance' is not defined"
     ]
    }
   ],
   "source": [
    "gt_dist_tensor = torch.tensor(ground_truth_distance)\n",
    "ang_tensor = torch.tensor(angles)\n",
    "origins_tensor = torch.tensor(origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pos, sample_ang, sample_org = getSamples(origins_tensor, ang_tensor, gt_dist_tensor, num_bins=100)\n",
    "upsample_pos, upsample_ang, upsample_gt_distance = getUpSamples(origins_tensor, ang_tensor, gt_dist_tensor, num_rolls=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tile distances\n",
    "gt_distance_tiled = torch.tensor(repeat(ground_truth_distance, 'b -> (b n) 1', n=100))\n",
    "\n",
    "# stack the upsampled position to sampled positions\n",
    "pos = (torch.vstack((sample_pos, upsample_pos)))\n",
    "ang = (torch.vstack((sample_ang, upsample_ang)))\n",
    "gt_dis = (torch.vstack((gt_distance_tiled,upsample_gt_distance)))\n",
    "org = (torch.vstack((sample_org, upsample_pos)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45895/3882400413.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  temp = torch.tensor((sample_positions - origins)**2)\n"
     ]
    }
   ],
   "source": [
    "actual_value_sigmoided = (getTargetValues(pos, gt_dis, org)).to(dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns pytorch tensor of sigmoid of projected SDF\n",
    "def getTargetValues(sample_positions, gt_distance, origins, num_bins=100):\n",
    "    # calculate distance from sample_position\n",
    "    temp = torch.tensor((sample_positions - origins)**2)\n",
    "    pos_distance = torch.sqrt(torch.sum(temp, dim=1, keepdim=True))\n",
    "    \n",
    "    # find the \"projected\" value\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    values = sigmoid(-(pos_distance - gt_distance))\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unit_vectors(direction, focal_length, height, width, width_resolution = 1000, height_resolution = 1000):\n",
    "    \n",
    "    # Initialize the output array\n",
    "    unit_vectors = np.zeros((1000000, 3))\n",
    "    \n",
    "    # Compute the pixel coordinates\n",
    "    x_coords, y_coords = np.meshgrid(np.arange(height_resolution), np.arange(width_resolution))\n",
    "    x_coords = x_coords * (width / width_resolution)\n",
    "    y_coords = y_coords * (height / height_resolution)\n",
    "    \n",
    "    # Flatten the coordinates\n",
    "    x_coords = x_coords.flatten()\n",
    "    y_coords = y_coords.flatten()\n",
    "\n",
    "    # Compute the direction vectors\n",
    "    for i in range(height_resolution*width_resolution):\n",
    "        x = (x_coords[i] - width / 2)\n",
    "        y = (y_coords[i] - height / 2)\n",
    "        z = focal_length\n",
    "        vec = np.array([x, y, z])\n",
    "        unit_vectors[i] = vec / np.linalg.norm(vec)\n",
    "    return unit_vectors\n",
    "    # return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = generate_unit_vectors(np.array([1,0,0]),focal_length= 1, height = 0.5, width = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy array to an Open3D PointCloud object\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pts)\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar_nerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
