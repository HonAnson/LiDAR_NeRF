{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange, repeat\n",
    "import rosbags\n",
    "import json\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "from utility import listFiles\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from numpy import cos, sin\n",
    "### fucking around\n",
    "from pretrain import loadDataFromRegisteredSlam, cart2sph, preProcess\n",
    "from train import getSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data ... (1150/1187)"
     ]
    }
   ],
   "source": [
    "name = r'round_plant2'\n",
    "path = r'datasets/registered/' + name + r'.json'\n",
    "data = loadDataFromRegisteredSlam(path)\n",
    "training_data = preProcess(data)\n",
    "np.random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 30\n",
    "ground_truth_distance = training_data[:num_points,0]\n",
    "angles = training_data[:num_points,1:3]\n",
    "origins = training_data[:num_points,3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpacing(num_points, num_bins):\n",
    "    \"\"\"return a efewafwefwe\n",
    "    \"\"\"\n",
    "    # TODO: add hyperparameter for tuning \"slope\" of inverse sigmoid function\n",
    "    # create a list of magnitudes with even spacing from 0 to 1\n",
    "    t = torch.linspace(0,1, num_bins).expand(num_points, num_bins)  # [batch_size, num_bins//2]\n",
    "    \n",
    "    # preterb the spacing\n",
    "    mid = (t[:, :-1] + t[:, 1:]) / 2.\n",
    "    lower = torch.cat((t[:, :1], mid), -1)\n",
    "    upper = torch.cat((mid, t[:, -1:]), -1)\n",
    "    u = torch.rand(t.shape)\n",
    "    t = lower + (upper - lower) * u  # [batch_size, nb_bins//2]\n",
    "\n",
    "    # apply inverse sigmoid function to even spacing\n",
    "    t = torch.log(t / (1 - t))  \n",
    "    t = rearrange(t, 'a b -> (a b) 1')  # [num_bins, batch_size]  transpose for multiplication broadcast\n",
    "    return t  \n",
    "\n",
    "def getSamples(centres, angles, r, num_bins = 100):\n",
    "    num_points = r.shape[0]\n",
    "    elev = angles[:,0]\n",
    "    pan = angles[:,1]\n",
    "    x_tilde = cos(elev)*cos(pan)      \n",
    "    y_tilde = cos(elev)*sin(pan)      \n",
    "    z_tilde = sin(elev)\n",
    "    unit_vectors = torch.tensor([x_tilde, y_tilde, z_tilde])\n",
    "\n",
    "    # process vectors: [3, num_points] -> [num_points*num_bins, 3]\n",
    "    unit_vectors_repeated = repeat(unit_vectors, 'c n -> (n b) c', b = num_bins)\n",
    "    r_repeated = repeat(r, 'n -> (n b) 1', b = num_bins)\n",
    "    t = getSpacing(num_points, num_bins)\n",
    "    sample_magnitudes = t + r_repeated\n",
    "    pos = unit_vectors_repeated*sample_magnitudes      # [num_bins*num_points, 3]\n",
    "\n",
    "    # tile the origin values\n",
    "    centres_tiled = torch.tensor(repeat(centres, 'n c -> (n b) c', b = num_bins)) # [num_bin*batch_size, 3]\n",
    "    # complete getting sample position by adding camera centre position to sampled position\n",
    "    pos = centres_tiled + pos\n",
    "\n",
    "    # tile the angle too\n",
    "    angles_tiled = torch.tensor(repeat(angles, 'n c -> (n b) c', b = num_bins))\n",
    "    return pos, angles_tiled, centres_tiled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pos, sample_ang, sample_org = getSamples(origins, angles, ground_truth_distance, num_bins=100)\n",
    "# sample_pos = getSamples(origins, angles, ground_truth_distance, num_bins=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.2510, -5.3099, -0.3636],\n",
       "        [ 9.2510, -5.3099, -0.3636],\n",
       "        [ 9.2510, -5.3099, -0.3636],\n",
       "        ...,\n",
       "        [ 5.1147, -5.1280, -0.0550],\n",
       "        [ 5.1147, -5.1280, -0.0550],\n",
       "        [ 5.1147, -5.1280, -0.0550]], dtype=torch.float64)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy array to an Open3D PointCloud object\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(sample_pos)\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar_nerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
