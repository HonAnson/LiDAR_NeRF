{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "import rosbags\n",
    "import json\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "from preprocess import listFiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, number of frames = 100\n"
     ]
    }
   ],
   "source": [
    "# file_path = 'datasets/json/box_plant1/box_plant1_frame300_400.json'\n",
    "# # Open and read the JSON file\n",
    "# with open(file_path, 'r') as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# # Now 'data' is a dictionary\n",
    "# num_key = len(data.keys())\n",
    "# if num_key > 0:\n",
    "#     print(f\"Data loaded, number of frames = {num_key}\")\n",
    "# frame = 350\n",
    "# points = np.array(data[str(frame)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quickVisualize(points):\n",
    "    \"\"\" Visualize pointcloud from numpy array\"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path):\n",
    "    # List all files in the specified path, ignoring directories\n",
    "    df = pd.read_csv(path)\n",
    "    points_xyz = df.to_numpy()\n",
    "    return points_xyz[:,8:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for handling entier point cloud\n",
    "def shortPassFilter(points, threshold = 10):\n",
    "    \"\"\" Filter points that are further than a distance away\"\"\"\n",
    "    distance = (points[:,0]**2 + points[:,1]**2 + points[:,2]**2)**0.5\n",
    "    mask = distance < threshold\n",
    "    return points[mask]\n",
    "\n",
    "# prepare path\n",
    "directory = r'datasets/json/box_plant1/'\n",
    "files = listFiles(directory)\n",
    "files.sort()\n",
    "\n",
    "# prepare frame 0 as reference\n",
    "path = directory + files[0]\n",
    "with open(path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "pts_frame_0 = np.array(data[str(0)])\n",
    "pts_frame_60 = np.array(data[str(60)])\n",
    "pts_frame_0 = shortPassFilter(pts_frame_0, 7)\n",
    "pts_frame_60 = shortPassFilter(pts_frame_60, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For handling manual point clouds\n",
    "path1 = r'datasets/box_plant1_manual_frame0.csv'\n",
    "path2 = r'datasets/box_plant1_manual_frame60.csv'\n",
    "pts_frame_0 = loadData(path1)\n",
    "pts_frame_60 = loadData(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Open3D PointCloud objects\n",
    "source = o3d.geometry.PointCloud()\n",
    "source.points = o3d.utility.Vector3dVector(pts_frame_0)\n",
    "\n",
    "target= o3d.geometry.PointCloud()\n",
    "target.points = o3d.utility.Vector3dVector(pts_frame_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Global Registration\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_plotly([source_temp, target_temp])\n",
    "\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "\n",
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "                0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    print(result.transformation)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n"
     ]
    }
   ],
   "source": [
    "voxel_size=0.05\n",
    "source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ransac = execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "print(result_ransac)\n",
    "draw_registration_result(source_down, target_down, result_ransac.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Applying ICP for local registration\n",
    "trans_init = np.asarray(result_ransac.transformation)\n",
    "threshold=0.02\n",
    "print(\"Apply point-to-point ICP\")\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar_nerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
